#!/usr/bin/env python3
"""
æµ‹è¯•LLMæ¨èç®—æ³•çš„è„šæœ¬ - ä½¿ç”¨Gemini APIï¼ˆé…ç½®åŒ–ç‰ˆæœ¬ï¼‰
"""

import os
import sys
from dotenv import load_dotenv
load_dotenv(override=True)

from recommender import llm_based_rerank_paper
from paper import ArxivPaper
from llm import set_global_llm
import arxiv
from loguru import logger
import yaml

def create_mock_corpus():
    """åˆ›å»ºæ¨¡æ‹Ÿçš„corpusæ•°æ®"""
    return [
        {
            'data': {
                'title': 'Embodied AI: A Survey on Integrating Perception and Action',
                'abstractNote': 'This paper presents a comprehensive survey of embodied artificial intelligence, focusing on the integration of perception and action in robotic systems. We discuss recent advances in vision-language models, world models, and their applications in robotics.',
                'dateAdded': '2024-01-15T10:00:00Z'
            }
        },
        {
            'data': {
                'title': 'Learning World Models for Robotic Manipulation',
                'abstractNote': 'We propose a novel approach for learning world models that can predict the effects of robotic actions in complex environments. Our method combines transformer architectures with reinforcement learning.',
                'dateAdded': '2024-01-10T09:00:00Z'
            }
        },
        {
            'data': {
                'title': 'Vision-Language Models for Robot Navigation',
                'abstractNote': 'This work explores the use of large vision-language models for robot navigation tasks. We demonstrate how natural language instructions can be grounded in visual observations.',
                'dateAdded': '2024-01-05T08:00:00Z'
            }
        }
    ]

def create_mock_candidates():
    """åˆ›å»ºæ¨¡æ‹Ÿçš„å€™é€‰è®ºæ–‡"""
    # åˆ›å»ºä¸€äº›æ¨¡æ‹Ÿçš„arxiv.Resultå¯¹è±¡
    class MockArxivResult:
        def __init__(self, title, summary, arxiv_id):
            self.title = title
            self.summary = summary
            self._arxiv_id = arxiv_id
            self.authors = []
            self.pdf_url = f"https://arxiv.org/pdf/{arxiv_id}.pdf"
        
        def get_short_id(self):
            return self._arxiv_id
    
    mock_results = [
        MockArxivResult(
            "Multimodal Foundation Models for Robotic Manipulation",
            "We present a multimodal foundation model that can understand both visual and textual instructions for robotic manipulation tasks. Our approach leverages large-scale pretraining on internet data to develop generalizable robotic skills.",
            "2024.0001"
        ),
        MockArxivResult(
            "Deep Reinforcement Learning for Autonomous Driving",
            "This paper proposes a deep reinforcement learning approach for autonomous driving in urban environments. We use a transformer-based world model to predict future states and plan optimal trajectories.",
            "2024.0002"  
        ),
        MockArxivResult(
            "Attention Mechanisms in Natural Language Processing",
            "We study various attention mechanisms used in transformer models for natural language processing tasks. Our analysis focuses on computational efficiency and model interpretability.",
            "2024.0003"
        ),
        MockArxivResult(
            "Embodied Question Answering with Vision-Language Models", 
            "We introduce a new framework for embodied question answering that combines vision-language models with robotic exploration. Our agent can navigate environments and answer questions about observed objects.",
            "2024.0004"
        ),
        MockArxivResult(
            "Graph Neural Networks for Social Network Analysis",
            "This work applies graph neural networks to social network analysis problems. We demonstrate improved performance on node classification and link prediction tasks.",
            "2024.0005"
        )
    ]
    
    return [ArxivPaper(result) for result in mock_results]

def load_test_config():
    """ä»é…ç½®æ–‡ä»¶åŠ è½½æµ‹è¯•å‚æ•°"""
    config_file = "private_config.yaml"
    if os.path.exists(config_file):
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            
            if 'LLM_RECOMMENDER' in config:
                return {
                    'research_interests': config['LLM_RECOMMENDER'].get('RESEARCH_INTERESTS'),
                    'corpus_batch_size': config['LLM_RECOMMENDER'].get('CORPUS_BATCH_SIZE', 20),
                    'candidate_batch_size': config['LLM_RECOMMENDER'].get('CANDIDATE_BATCH_SIZE', 8),
                    'keyword_bonus': config['LLM_RECOMMENDER'].get('KEYWORD_BONUS', 2.0),
                    'default_score': config['LLM_RECOMMENDER'].get('DEFAULT_SCORE', 5.0)
                }
    
    # é»˜è®¤é…ç½®
    return {
        'research_interests': [
            "embodied AI", "robotics", "world model", 
            "multimodal learning", "vision-language models"
        ],
        'corpus_batch_size': 10,
        'candidate_batch_size': 3,
        'keyword_bonus': 2.0,
        'default_score': 5.0
    }

def main():
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logger.remove()
    logger.add(sys.stdout, level="INFO")
    
    print("ğŸš€ å¼€å§‹æµ‹è¯•LLMæ¨èç®—æ³•ï¼ˆä½¿ç”¨Gemini API + é…ç½®åŒ–ç‰ˆæœ¬ï¼‰...")
    
    # é…ç½®Gemini APIå‚æ•°
    gemini_api_key = "AIzaSyDijBhdh2Hj-D6C-iaTatB_5zvX9C5YRi0"
    gemini_base_url = "https://generativelanguage.googleapis.com/v1beta/openai/"
    gemini_model = "gemini-2.0-flash"
    
    # ä¹Ÿå¯ä»¥ä»ç¯å¢ƒå˜é‡è·å–ï¼Œå¦‚æœè®¾ç½®äº†çš„è¯
    api_key = os.getenv('GEMINI_API_KEY', gemini_api_key)
    base_url = os.getenv('GEMINI_BASE_URL', gemini_base_url)
    model_name = os.getenv('GEMINI_MODEL', gemini_model)
    
    if not api_key or api_key == "your-api-key-here":
        print("âŒ è¯·é…ç½®æœ‰æ•ˆçš„Gemini APIå¯†é’¥")
        print("å¯ä»¥åœ¨è„šæœ¬ä¸­ç›´æ¥è®¾ç½®ï¼Œæˆ–è€…è®¾ç½®ç¯å¢ƒå˜é‡GEMINI_API_KEY")
        return
    
    # è®¾ç½®LLMä¸ºGemini
    try:
        set_global_llm(
            api_key=api_key,
            base_url=base_url,
            model=model_name,
            lang='Chinese'
        )
        print(f"âœ… Gemini LLMè®¾ç½®æˆåŠŸ")
        print(f"   API Base URL: {base_url}")
        print(f"   Model: {model_name}")
    except Exception as e:
        print(f"âŒ Gemini LLMè®¾ç½®å¤±è´¥: {e}")
        return
    
    # åŠ è½½æµ‹è¯•é…ç½®
    test_config = load_test_config()
    print(f"\nâš™ï¸  æµ‹è¯•é…ç½®:")
    print(f"   ç ”ç©¶å…´è¶£é¢†åŸŸ: {len(test_config['research_interests'])} ä¸ª")
    print(f"   Corpusæ‰¹å¤§å°: {test_config['corpus_batch_size']}")
    print(f"   å€™é€‰è®ºæ–‡æ‰¹å¤§å°: {test_config['candidate_batch_size']}")
    print(f"   å…³é”®è¯åŠ åˆ†: {test_config['keyword_bonus']}")
    print(f"   é»˜è®¤åˆ†æ•°: {test_config['default_score']}")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    corpus = create_mock_corpus()
    candidates = create_mock_candidates()
    
    # æ¨¡æ‹Ÿä¸€ç¯‡æœ‰å…³é”®è¯çš„è®ºæ–‡
    candidates[0].search_keyword = "robot manipulation"
    
    print(f"\nğŸ“š CorpusåŒ…å« {len(corpus)} ç¯‡è®ºæ–‡")
    print(f"ğŸ“„ å€™é€‰è®ºæ–‡åŒ…å« {len(candidates)} ç¯‡")
    print(f"ğŸ”‘ å…¶ä¸­ 1 ç¯‡è®ºæ–‡åŒ¹é…å…³é”®è¯ï¼ˆå°†è·å¾— +{test_config['keyword_bonus']} åˆ†åŠ æˆï¼‰")
    
    # è¿è¡ŒLLMæ¨è
    try:
        print("\nğŸ¤– å¼€å§‹ä½¿ç”¨Geminiè¿›è¡Œé…ç½®åŒ–LLMæ¨è...")
        ranked_papers = llm_based_rerank_paper(
            candidates, 
            corpus,
            research_interests=test_config['research_interests'],
            corpus_batch_size=test_config['corpus_batch_size'],
            candidate_batch_size=test_config['candidate_batch_size'],
            keyword_bonus=test_config['keyword_bonus'],
            default_score=test_config['default_score']
        )
        
        print("\nğŸ“Š æ¨èç»“æœï¼š")
        print("=" * 80)
        for i, paper in enumerate(ranked_papers, 1):
            score = getattr(paper, 'score', 0)
            reason = getattr(paper, 'llm_reason', 'æ— ç†ç”±')
            keyword_mark = " ğŸ”‘" if paper.search_keyword else ""
            print(f"{i}. ã€è¯„åˆ†: {score:.1f}ã€‘{keyword_mark}")
            print(f"   æ ‡é¢˜: {paper.title}")
            print(f"   ç†ç”±: {reason}")
            if paper.search_keyword:
                print(f"   å…³é”®è¯: {paper.search_keyword}")
            print(f"   æ‘˜è¦: {paper.summary[:100]}...")
            print("-" * 80)
        
        print("âœ… Geminié…ç½®åŒ–æ¨èæµ‹è¯•å®Œæˆï¼")
        
        # åˆ†æç»“æœ
        scores = [getattr(p, 'score', 0) for p in ranked_papers]
        print(f"\nğŸ“ˆ è¯„åˆ†åˆ†æ:")
        print(f"   æœ€é«˜åˆ†: {max(scores):.1f}")
        print(f"   æœ€ä½åˆ†: {min(scores):.1f}")
        print(f"   å¹³å‡åˆ†: {sum(scores)/len(scores):.1f}")
        print(f"   è¯„åˆ†èŒƒå›´: {max(scores) - min(scores):.1f}")
        
        # æ£€æŸ¥å…³é”®è¯åŠ åˆ†æ˜¯å¦ç”Ÿæ•ˆ
        keyword_papers = [p for p in ranked_papers if p.search_keyword]
        if keyword_papers:
            print(f"   å…³é”®è¯è®ºæ–‡åˆ†æ•°: {[p.score for p in keyword_papers]}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¥½çš„åŒºåˆ†åº¦
        if max(scores) - min(scores) > 2:
            print("âœ… è¯„åˆ†åŒºåˆ†åº¦è‰¯å¥½ï¼Œæ¨èç®—æ³•å·¥ä½œæ­£å¸¸")
        else:
            print("âš ï¸  è¯„åˆ†åŒºåˆ†åº¦è¾ƒå°ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ç®—æ³•å‚æ•°")
        
    except Exception as e:
        print(f"âŒ æ¨èè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 